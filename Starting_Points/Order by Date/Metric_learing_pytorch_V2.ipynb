{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrfEDWBK0nyD",
        "outputId": "8081e286-5375-4617-e5c6-cc848343e995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0gKUzSdSQFM",
        "outputId": "eb43d2ad-62f8-4b1f-ee71-b87d527e4f52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch-metric-learning\n",
            "  Downloading pytorch_metric_learning-2.5.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.1/119.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (4.66.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->pytorch-metric-learning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-metric-learning\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pytorch-metric-learning-2.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-metric-learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyW8iYzp2SO8",
        "outputId": "f530eb42-3fcc-4688-cdc6-37cfebbb050a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         artist  date                  genre  pixelsx  pixelsy  size_bytes  \\\n",
            "0  Paul Gauguin  1903         genre painting   1916.0   1688.0    363138.0   \n",
            "1  Paul Gauguin  1893               portrait   2048.0   1348.0    293452.0   \n",
            "2  Paul Gauguin  1892  mythological painting   1800.0   1082.0   1638911.0   \n",
            "3  Paul Gauguin  1903         genre painting   1600.0   1067.0    307130.0   \n",
            "4  Paul Gauguin  1892               portrait   1096.0   1476.0    467406.0   \n",
            "\n",
            "    source               style                  title    artist_group  \\\n",
            "0  wikiart  Post-Impressionism         The Invocation  train_and_test   \n",
            "1  wikiart         Cloisonnism                  Alone  train_and_test   \n",
            "2  wikiart         Cloisonnism          The Royal End  train_and_test   \n",
            "3  wikiart  Post-Impressionism  Women and white horse  train_and_test   \n",
            "4  wikiart  Post-Impressionism            Two sisters  train_and_test   \n",
            "\n",
            "   in_train new_filename  \n",
            "0     False    35323.jpg  \n",
            "1     False    73683.jpg  \n",
            "2      True   101871.jpg  \n",
            "3      True    76989.jpg  \n",
            "4     False    89439.jpg  \n",
            "Number of classes: 90\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
        "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
        "\n",
        "folder = '/content/drive/My Drive/PROJECTE DEEP LEARNING/TOP5_ARTISTS_WITH_100_PICTURES'\n",
        "\n",
        "# List the files in the folder\n",
        "all_pictures = os.listdir(folder)\n",
        "\n",
        "file_path = \"/content/drive/My Drive/PROJECTE DEEP LEARNING/TOP5_ARTISTS_WITH_100_PICTURES.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "\n",
        "NUM_CLASSES = len(df['date'].unique().tolist())\n",
        "\n",
        "print(\"Number of classes:\", NUM_CLASSES)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjqeDaDUSOwY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LjftRfrGal7",
        "outputId": "ddd76704-823c-4ece-b907-dc2b8b7f9547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN and TEST folders already exist. Reading train and test DataFrames from CSV files...\n",
            "Train DataFrame: (355, 2)\n",
            "Test DataFrame: (145, 2)\n"
          ]
        }
      ],
      "source": [
        "# GROUP THE FILES BY EACH date\n",
        "import random\n",
        "def group_files_per_date():\n",
        "  data_per_date = {}\n",
        "\n",
        "  # Iterate over each row of the DataFrame\n",
        "  for index, row in df.iterrows():\n",
        "      date = row['date']\n",
        "      new_filename = row['new_filename']\n",
        "\n",
        "      # Check if the date is already in the dictionary\n",
        "      if date in data_per_date:\n",
        "          # Add the new_filename to the existing list of the date\n",
        "          data_per_date[date].append(new_filename)\n",
        "      else:\n",
        "          # Create a new list for the date and add the new_filename\n",
        "          data_per_date[date] = [new_filename]\n",
        "\n",
        "  return data_per_date\n",
        "\n",
        "# SPLIT THE FILES INTO TRAIN AND TEST SETS (CREATE NEW DATASETS)\n",
        "def split_test_train(data_per_date, train_percentage = 0.8):\n",
        "\n",
        "  TRAIN_names = []\n",
        "  TEST_names = []\n",
        "\n",
        "  # Iterate over each date and their 'new_filename'\n",
        "  for date, filenames in data_per_date.items():\n",
        "      # Calculate the number of files for training and testing\n",
        "      total_files = len(filenames)\n",
        "      num_train = int(train_percentage * total_files)\n",
        "\n",
        "      # Shuffle the filenames to avoid selection biases\n",
        "      random.shuffle(filenames)\n",
        "\n",
        "      # Divide the filenames into train and test\n",
        "      train_filenames = filenames[:num_train]\n",
        "      test_filenames = filenames[num_train:]\n",
        "\n",
        "      # Store the divided filenames into train and test\n",
        "      TRAIN_names.extend(train_filenames)\n",
        "      TEST_names.extend(test_filenames)\n",
        "  return TRAIN_names, TEST_names\n",
        "\n",
        "\n",
        "\n",
        "# CREATE TEST and TRAIN folders\n",
        "def create_train_test_folders(folder, TRAIN_names, TEST_names):\n",
        "    # Output folder for TRAIN and TEST\n",
        "    train_folder = os.path.join(folder, 'TRAIN')\n",
        "    test_folder = os.path.join(folder, 'TEST')\n",
        "\n",
        "    # Create TRAIN and TEST folders if they don't exist\n",
        "    os.makedirs(train_folder, exist_ok=True)\n",
        "    os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "    # Move images from TRAIN to TRAIN folder\n",
        "    for filename in TRAIN_names:\n",
        "        src = os.path.join(folder, filename)\n",
        "        dst = os.path.join(train_folder, filename)\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "    # Move images from TEST to TEST folder\n",
        "    for filename in TEST_names:\n",
        "        src = os.path.join(folder, filename)\n",
        "        dst = os.path.join(test_folder, filename)\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "    # Create df_train with rows whose 'new_filename' is in TRAIN_names and keep only 'date' and 'new_filename' columns\n",
        "    train_dataframe = df[df['new_filename'].isin(TRAIN_names)][['date', 'new_filename']]\n",
        "    # File path for the CSV file\n",
        "    file_path = os.path.join(folder, 'train_dataframe.csv')\n",
        "    # Save the DataFrame as CSV\n",
        "    train_dataframe.to_csv(file_path, index=False)\n",
        "\n",
        "    # Create df_test with rows whose 'new_filename' is in TEST_names and keep only 'date' and 'new_filename' columns\n",
        "    test_dataframe = df[df['new_filename'].isin(TEST_names)][['date', 'new_filename']]\n",
        "    # File path for the CSV file\n",
        "    file_path = os.path.join(folder, 'test_dataframe.csv')\n",
        "    # Save the DataFrame as CSV\n",
        "    test_dataframe.to_csv(file_path, index=False)\n",
        "\n",
        "    return train_dataframe, test_dataframe\n",
        "\n",
        "if not (os.path.exists(os.path.join(folder, 'TRAIN')) and os.path.exists(os.path.join(folder, 'TEST')) and os.path.exists(os.path.join(folder, 'train_dataframe.csv'))):\n",
        "  # Group files per date\n",
        "  data_per_date = group_files_per_date()\n",
        "  # Print the number of files for each date\n",
        "  print(\"- date and numer of images:\")\n",
        "  for key in data_per_date.keys():\n",
        "    print(key, len(data_per_date[key]))\n",
        "\n",
        "  # Split data\n",
        "  TRAIN_names, TEST_names = split_test_train(data_per_date)\n",
        "\n",
        "  # Use the function to create TRAIN and TEST folders\n",
        "  train_dataframe, test_dataframe = create_train_test_folders(folder, TRAIN_names, TEST_names)\n",
        "  print(\"\\nImages successfully moved to TRAIN and TEST folders.\")\n",
        "else:\n",
        "  print(\"TRAIN and TEST folders already exist. Reading train and test DataFrames from CSV files...\")\n",
        "\n",
        "  # Read train and test DataFrames from CSV files\n",
        "  train_csv_path = os.path.join(folder, 'train_dataframe.csv')\n",
        "  test_csv_path = os.path.join(folder, 'test_dataframe.csv')\n",
        "  train_dataframe = pd.read_csv(train_csv_path)\n",
        "  test_dataframe = pd.read_csv(test_csv_path)\n",
        "\n",
        "  print(\"Train DataFrame:\", train_dataframe.shape)\n",
        "  print(\"Test DataFrame:\", test_dataframe.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDdlPgkCUdkU"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "Image.MAX_IMAGE_PIXELS = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzsZlavWVT_v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zxO1m994HJS0"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the transformation to convert images to PyTorch tensors\n",
        "transf = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Paths of the training and testing folders\n",
        "train_folder = '/content/drive/My Drive/PROJECTE DEEP LEARNING/TOP5_ARTISTS_WITH_100_PICTURES/TRAIN'\n",
        "test_folder = '/content/drive/My Drive/PROJECTE DEEP LEARNING/TOP5_ARTISTS_WITH_100_PICTURES/TEST'\n",
        "\n",
        "# Get the file names of training and testing images from the dataframes\n",
        "train_filenames = train_dataframe['new_filename'].tolist()\n",
        "test_filenames = test_dataframe['new_filename'].tolist()\n",
        "\n",
        "\n",
        "# Create empty lists for images and labels\n",
        "train_images = []\n",
        "train_labels = []\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "# Load training images\n",
        "for filename in train_filenames:\n",
        "    img_path = os.path.join(train_folder, filename)\n",
        "    img = Image.open(img_path)\n",
        "    img_tensor = transf(img)\n",
        "    train_images.append(img_tensor)\n",
        "    # Get label from the dataframe\n",
        "    label = train_dataframe[train_dataframe['new_filename'] == filename]['date'].iloc[0]\n",
        "    train_labels.append(label)\n",
        "# Load testing images\n",
        "for filename in test_filenames:\n",
        "    img_path = os.path.join(test_folder, filename)\n",
        "    img = Image.open(img_path)\n",
        "    img_tensor = transf(img)\n",
        "    test_images.append(img_tensor)\n",
        "    # Get label from the dataframe\n",
        "    label = test_dataframe[test_dataframe['new_filename'] == filename]['date'].iloc[0]\n",
        "    test_labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uW2I1fQee46Y",
        "outputId": "c0dd5ab7-6685-4cd5-d7fa-36e392fd89eb"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'if' statement on line 30 (<ipython-input-9-92df4d18ec29>, line 33)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-92df4d18ec29>\"\u001b[0;36m, line \u001b[0;32m33\u001b[0m\n\u001b[0;31m    for filename in train_filenames:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 30\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
        "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
        "\n",
        "# Define the transformation to convert images to PyTorch tensors\n",
        "transf = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization for color images\n",
        "])\n",
        "# Paths of the training and testing folders\n",
        "train_folder = '/content/drive/My Drive/PROJECTE DEEP LEARNING/TOP5_ARTISTS_WITH_100_PICTURES/TRAIN'\n",
        "test_folder = '/content/drive/My Drive/PROJECTE DEEP LEARNING/TOP5_ARTISTS_WITH_100_PICTURES/TEST'\n",
        "\n",
        "# Get the file names of training and testing images from the dataframes\n",
        "train_filenames = train_dataframe['new_filename'].tolist()\n",
        "test_filenames = test_dataframe['new_filename'].tolist()\n",
        "# Create empty lists for images and labels\n",
        "train_images = []\n",
        "train_labels = []\n",
        "test_images = []\n",
        "test_labels = []\n",
        "if not (os.path.exists(os.path.join(folder, 'TRAIN')) and os.path.exists(os.path.join(folder, 'TEST'))):\n",
        "\n",
        "  # Load training images\n",
        "for filename in train_filenames:\n",
        "    img_path = os.path.join(train_folder, filename)\n",
        "    img = Image.open(img_path)\n",
        "    img_tensor = transf(img)\n",
        "    train_images.append(img_tensor)\n",
        "    # Get label from the dataframe\n",
        "    label = train_dataframe[train_dataframe['new_filename'] == filename]['date'].iloc[0]\n",
        "    train_labels.append(label)\n",
        "\n",
        "# Load testing images\n",
        "for filename in test_filenames:\n",
        "    img_path = os.path.join(test_folder, filename)\n",
        "    img = Image.open(img_path)\n",
        "    img_tensor = transf(img)\n",
        "    test_images.append(img_tensor)\n",
        "    # Get label from the dataframe\n",
        "    label = test_dataframe[test_dataframe['new_filename'] == filename]['date'].iloc[0]\n",
        "    test_labels.append(label)\n",
        "\n",
        "# Convert labels to tensor\n",
        "train_labels_tensor = torch.tensor(train_labels, dtype=torch.float32)\n",
        "test_labels_tensor = torch.tensor(test_labels, dtype=torch.float32)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_dataset = TensorDataset(torch.stack(train_images), train_labels_tensor)\n",
        "test_dataset = TensorDataset(torch.stack(test_images), test_labels_tensor)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FGc92zURgS-U"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def show_images(dataset, labels, class_name, num_images=4):\n",
        "    # Find indices of images belonging to the specified class\n",
        "    class_indices = [idx for idx, label in enumerate(labels) if label == class_name]\n",
        "    # Randomly select 4 indices\n",
        "    selected_indices = np.random.choice(class_indices, num_images, replace=False)\n",
        "\n",
        "    # Plot the images\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
        "    fig.suptitle(f\"Class {class_name} Images\")\n",
        "    for i, idx in enumerate(selected_indices):\n",
        "        img, label = dataset[idx]\n",
        "        img = img.permute(1, 2, 0)  # Convert from (C, H, W) to (H, W, C) for visualization\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example: Show 4 images of class 0 from the training set\n",
        "show_images(train_dataset, train_labels_tensor, class_name=1887)\n",
        "\n",
        "# Example: Show 4 images of class 1 from the testing set\n",
        "show_images(test_dataset, test_labels_tensor, class_name=1887)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BSwC1VOahl65"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class NGDSLoss(torch.nn.Module):\n",
        "    def __init__(self, margin=0.2):\n",
        "        super(NGDSLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, embeddings, labels):\n",
        "        pairwise_distances = torch.cdist(embeddings, embeddings, p=2)\n",
        "        same_class_mask = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
        "        diff_class_mask = ~same_class_mask\n",
        "        same_class_distances = pairwise_distances.masked_select(same_class_mask)\n",
        "        diff_class_distances = pairwise_distances.masked_select(diff_class_mask)\n",
        "\n",
        "        loss = torch.relu(self.margin - torch.mean(same_class_distances)) + torch.mean(diff_class_distances)\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HnhA32YVXYSy"
      },
      "outputs": [],
      "source": [
        "from pytorch_metric_learning.losses import SelfSupervisedLoss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1gXG7Ki8epz2"
      },
      "outputs": [],
      "source": [
        "# Definición de la pérdida NGDS\n",
        "class NGDSLoss(nn.Module):\n",
        "    def __init__(self, margin=0.1):  # Ajustar el margen\n",
        "        super(NGDSLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, embeddings, labels, indices_tuple):\n",
        "        anchor, positive, negative = indices_tuple\n",
        "        pos_distances = torch.norm(embeddings[anchor] - embeddings[positive], dim=1)\n",
        "        neg_distances = torch.norm(embeddings[anchor] - embeddings[negative], dim=1)\n",
        "        losses = F.relu(pos_distances - neg_distances + self.margin)\n",
        "        return losses.mean()\n",
        "\n",
        "# Define the CNN for feature extraction\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        # Calculate the output size after convolutions and pooling\n",
        "        self.fc_input_size = self.calculate_fc_input_size()\n",
        "        self.fc1 = nn.Linear(self.fc_input_size, 128)\n",
        "\n",
        "    def calculate_fc_input_size(self):\n",
        "        # Sample input tensor to calculate output size\n",
        "        input_tensor = torch.randn(1, 3, 224, 224)  # Assuming input size of 224x224\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "        return x.view(x.size(0), -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, miner, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Ajustar la tasa de aprendizaje\n",
        "loss_func = SelfSupervisedLoss(TripletMarginLoss())\n",
        "\n",
        "#loss_func = NGDSLoss(margin=0.1)  # Utiliza la función de pérdida NGDS en lugar de TripletMarginLoss\n",
        "distance = distances.CosineSimilarity()  # Define the distance metric\n",
        "mining_func = miners.TripletMarginMiner(margin=0.1, distance=distance, type_of_triplets=\"hard\")\n",
        "\n",
        "# Function to compute accuracy\n",
        "def compute_accuracy(test_embeddings, test_labels, train_embeddings, train_labels, k=1):\n",
        "    correct = 0\n",
        "    total = len(test_embeddings)\n",
        "    for i, test_emb in enumerate(test_embeddings):\n",
        "        distances = []\n",
        "        for train_emb in train_embeddings:\n",
        "            dist = torch.norm(test_emb - train_emb, p=2)\n",
        "            distances.append(dist.item())\n",
        "        # Obtener los índices de los k vecinos más cercanos\n",
        "        nearest_indices = sorted(range(len(distances)), key=lambda i: distances[i])[:k]\n",
        "        # Obtener las etiquetas de los vecinos más cercanos\n",
        "        nearest_labels = [train_labels[idx] for idx in nearest_indices]\n",
        "        # Comprobar si la etiqueta de la instancia de prueba está entre las k vecinas más cercanas\n",
        "        if test_labels[i] in nearest_labels:\n",
        "            correct += 1\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Training loop\n",
        "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        embeddings = model(data)\n",
        "        indices_tuple = mining_func(embeddings, labels)\n",
        "        loss = loss_func(embeddings, labels, indices_tuple)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 20 == 0:\n",
        "            print(f\"Epoch {epoch} Iteration {batch_idx}: Loss = {loss}, Number of mined triplets = {mining_func.num_triplets}\")\n",
        "\n",
        "# Function to get all embeddings\n",
        "def get_all_embeddings(dataset, model, device):\n",
        "    model.eval()\n",
        "    embeddings_list = []\n",
        "    labels_list = []\n",
        "    with torch.no_grad():\n",
        "        for data, labels in DataLoader(dataset, batch_size=50):\n",
        "            data = data.to(device)\n",
        "            embeddings = model(data)\n",
        "            embeddings_list.append(embeddings.cpu())\n",
        "            labels_list.append(labels)\n",
        "    return torch.cat(embeddings_list), torch.cat(labels_list)\n",
        "\n",
        "# Testing loop\n",
        "def test(train_set, test_set, model, device, k=1):\n",
        "    train_embeddings, train_labels = get_all_embeddings(train_set, model, device)\n",
        "    test_embeddings, test_labels = get_all_embeddings(test_set, model, device)\n",
        "    print(\"Computing accuracy\")\n",
        "    accuracy = compute_accuracy(test_embeddings, test_labels, train_embeddings, train_labels, k)\n",
        "    print(f\"Test set accuracy (Precision@1) = {accuracy}\")\n",
        "    return accuracy\n",
        "\n",
        "# Testing and evaluation loop\n",
        "num_epochs = 10\n",
        "epoch_accuracies = []\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train(model, loss_func, mining_func, device, train_loader, optimizer, epoch)\n",
        "    epoch_accuracy = test(train_dataset, test_dataset, model, device)\n",
        "    epoch_accuracies.append(epoch_accuracy)\n",
        "    print(f\"Epoch {epoch} Accuracy = {epoch_accuracy}\")\n",
        "\n",
        "# Print accuracy for each epoch\n",
        "print(\"Accuracy per epoch:\", epoch_accuracies)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6nM0s4Ofkszi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7SyINCHWHU9b"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TWEeCWtzbHQR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ccU9Fvc0bH1f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fjSThdtYGO9X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9XbfHY4gHsGP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7WZFgNiGHwVA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8ai9wiUxH0qG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
